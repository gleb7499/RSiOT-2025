---
title: "Лекция 11 — Очереди и стриминг событий"
author: "Профессор‑практик"
date: 2025-11-30
---

# Лекция 11. Очереди и стриминг

## Заголовок и контекст
Кратко: сравнение моделей доставки сообщений и потоковой обработки: очереди (RabbitMQ/AMQP), журнальные стримы (Kafka) и pub/sub брокеры. Почему выбор влияет на порядок, масштаб и гарантию доставки.

## Результаты обучения (3–6)
- Понять различия очередь vs лог‑стрим vs pub/sub.
- Настроить базовый продюсер/консюмер Kafka с управлением offset.
- Оценивать семантики доставки (at‑most/at‑least/exactly‑once) и их стоимость.
- Применять DLQ и стратегию повторов с backoff.
- Диагностировать проблемы порядка и потери сообщений.

## Пререквизиты
- Базовое понимание TCP, понятий брокер/клиент.
- Минимальный опыт работы с Docker / контейнерами.

## Введение: картина мира
IoT/микросервисы порождают события: нужно гарантировать доставку, порядок, масштаб. Очередь отлично подходит для конкурирующих потребителей без жёстких требований к повторному чтению истории. Лог‑стрим (Kafka) хорош для реплей/исторического анализа и масштабного параллелизма.
Аналогия: очередь — конвейер с коробками (каждая коробка уходит один раз); лог‑стрим — архив ленты, к которой можно вернуться и перемотать.

## Основные понятия и терминология
Определения:
- **Очередь**: структура FIFO, сообщение потребляется единожды.
- **Лог‑стрим (commit log)**: неизменяемая упорядоченная последовательность записей с возможностью пере-чтения.
- **Pub/Sub**: модель распространения сообщений подписчикам по темам.
- **Offset**: позиция сообщения в партиции лог‑стрима.
Контра‑примеры: очередь не позволяет легко реплей событий; лог‑стрим без управления ростом может переполнить диск.

## Пошаговое освоение темы

### Подтема 1. Модели обмена: очередь, pub/sub, лог‑стррим
Определения:
- **Exclusive consumer**: единственный потребитель для данного канала.
- **Fan‑out**: доставка копии сообщения каждому подписчику.
- **Retention**: политика хранения сообщений (время/размер).

Мини‑пример (RabbitMQ декларация очереди):
```bash
rabbitmqadmin declare queue name=events durable=true
```
Пояснение: создаёт устойчивую очередь, где сообщения переживают рестарт брокера.
Проверка: отправить тестовое сообщение и получить его через `rabbitmqadmin get queue=events`.
Типичные ошибки:
- отсутствие durable приводит к потере сообщений при рестарте;
- смешивание рабочих и широковещательных потоков в одной очереди.

### Подтема 2. Архитектура Kafka: брокеры, партиции, ISR
Определения:
- **Broker**: процесс Kafka, хранящий партиции.
- **Partition**: горизонтальное деление топика для параллелизма.
- **ISR (In‑Sync Replicas)**: реплики партиции, синхронизированные с лидером.
- **Replication Factor (RF)**: число реплик партиции.

Мини‑пример (создание топика):
```bash
kafka-topics.sh --create --topic telemetry --partitions 3 --replication-factor 3 --bootstrap-server localhost:9092
```
Пояснение: создаёт топик с 3 партициями и RF=3 — повышает устойчивость и параллелизм.
Проверка: `kafka-topics.sh --describe --topic telemetry --bootstrap-server localhost:9092` — убедиться что каждая партиция имеет ISR=3.
Типичные ошибки:
- слишком мало партиций → узкое место по throughput;
- высокий RF без нужды → избыточные затраты на хранение.

### Подтема 3. Семантики доставки: at‑most, at‑least, exactly‑once
Определения:
- **At‑most‑once**: сообщение обрабатывается 0 или 1 раз (риск потери).
- **At‑least‑once**: гарантирована обработка ≥1 раза (риск дубликата).
- **Exactly‑once**: логически один результат, достигается через идемпотентность + транзакции.

Мини‑пример (конфиг идемпотентного продюсера Kafka):
```bash
enable.idempotence=true
acks=all
retries=5
```
Пояснение: уменьшает риск дубликатов и повышает гарантии доставки.
Проверка: отправить одно и то же сообщение многократно — потребитель должен видеть одно логическое событие при корректной дедупликации.
Типичные ошибки:
- путать доставку exactly‑once со сложной бизнес‑логикой без ключей;
- отключать `acks=all`, снижая надёжность.

### Подтема 4. Consumer groups и ребалансировка
Определения:
- **Consumer Group**: набор потребителей, совместно читающих партиции топика.
- **Rebalance**: перераспределение партиций между потребителями при изменении группы.
- **Sticky / Cooperative**: режимы минимизации перестановок при ребалансе.

Мини‑пример (изоляция offset по группе):
```bash
kafka-console-consumer.sh --topic telemetry --group analytics --bootstrap-server localhost:9092
```
Пояснение: потребитель использует группу `analytics`; Kafka ведёт offset‑прогресс отдельно.
Проверка: запустить второй консюмер с тем же group — сообщения распределятся.
Типичные ошибки:
- частые рестарты → постоянные ребалансы и задержки;
- отсутствие управления max.poll.interval.ms.

### Подтема 5. Offset менеджмент и шаблон at‑least‑once
Определения:
- **Auto commit**: автоматическая фиксация offset по таймеру.
- **Manual commit**: фиксация после успешной обработки.
- **Redelivery**: повторная доставка при отсутствии commit.

Мини‑пример (псевдо‑код обработки):
```python
for record in consumer.poll():
		process(record)
		consumer.commit()  # ручной commit после обработки
```
Пояснение: ручной commit обеспечивает at‑least‑once семантику с возможным дубликатом при сбое после commit.
Проверка: искусственно выбросить исключение до commit — сообщение должно прийти повторно.
Типичные ошибки:
- commit до обработки → потеря данных при падении;
- слишком редкий commit → рост времени повторной обработки.

### Подтема 6. Порядок и ключи партиционирования
Определения:
- **Partition key**: значение для назначения сообщения партиции.
- **Ordering guarantee**: упорядоченность только внутри одной партиции.

Мини‑пример (отправка с ключом):
```bash
kafka-console-producer.sh --topic telemetry --bootstrap-server localhost:9092
>key1,{"temp":22}
>key1,{"temp":23}
```
Пояснение: сообщения с одинаковым ключом сохраняют локальный порядок.
Проверка: прочитать партицию и убедиться в порядке по `key1`.
Типичные ошибки:
- случайное использование случайных ключей → потеря семантики порядка;
- одна горячая партиция из-за популярного ключа.

### Подтема 7. Schema Registry и эволюция схем
Определения:
- **Schema Registry**: сервис хранения версий схем (Avro/JSON/Protobuf).
- **Compatibility**: политика совместимости (BACKWARD, FORWARD, FULL).

Мини‑пример (регистрация Avro схемы — псевдо):
```bash
curl -X POST http://localhost:8081/subjects/telemetry-value/versions \
	-H 'Content-Type: application/vnd.schemaregistry.v1+json' \
	-d '{"schema":"{\\"type\\":\\"record\\",\\"name\\":\\"Telemetry\\",\\"fields\\":[{\\"name\\":\\"temp\\",\\"type\\":\\"int\\"}]}"}'
```
Пояснение: сохраняет схему для значения топика; клиенты валидируют сообщения.
Проверка: попытаться зарегистрировать несовместимую схему — получить ошибку.
Типичные ошибки:
- отключенная совместимость → ломаются потребители;
- отсутствие контроля эволюции полей.

### Подтема 8. DLQ (Dead Letter Queue) и ретраи
Определения:
- **DLQ**: целевой топик/очередь для сообщений с ошибками обработки.
- **Backoff**: стратегия увеличения интервалов между повторными попытками.
- **Poison message**: сообщение, постоянно вызывающее сбой.

Мини‑пример (псевдо‑алгоритм ретрая):
```plaintext
try process(msg)
catch error -> if attempts < N publish retry; else send to DLQ
```
Пояснение: ограниченное число повторов защищает от бесконечной цикличности.
Проверка: сгенерировать сообщение с преднамеренной ошибкой — убедиться в попадании в DLQ после N попыток.
Типичные ошибки:
- отсутствие метрик повторов;
- бесконечные ретраи без DLQ.

## Разбор типичных ошибок и анти‑паттернов
- Over‑partitioning без нужды (много мелких партиций → overhead контроллера).
- Using auto commit для критичных сообщений (риск потери при сбое).
- Отсутствие идемпотентности при обработке повторов → дубликаты бизнес‑операций.
- Пропуск мониторинга DLQ → накопление ядовитых сообщений.

## Вопросы для самопроверки (12)
1. Чем очередь отличается от лог‑стрима по возможностям повторного чтения?
2. Какие плюсы и минусы у at‑least‑once доставки?
3. Зачем нужен ISR в Kafka?
4. Как влияет число партиций на параллелизм и порядок?
5. Почему exactly‑once почти всегда строится на идемпотентности?
6. Что даёт ручной commit offset?
7. Как выбрать ключ партиционирования?
8. Для чего нужен Schema Registry?
9. Что такое DLQ и когда её внедрять?
10. Как контролировать ретраи и backoff?
11. Какие риски у авто‑коммита offset?
12. В чём разница между Fan‑out и Consumer Group?

## Краткий конспект (cheat‑sheet)
- Типы: Queue (одно потребление) | Log stream (многократное чтение) | Pub/Sub (широкая рассылка).
- Доставка: at‑most (быстро, риск потерь) | at‑least (надёжно, дубликаты) | exactly‑once (дорого, сложность).
- Kafka продюсер: `enable.idempotence=true`, `acks=all`, настройка партиций.
- Offset: manual commit после успешной обработки.
- Порядок: гарантирован внутри партиции по ключу.
- Schema evolution: контролировать совместимость (BACKWARD/FORWARD/FULL).
- DLQ: лимит ретраев + метрики.

## Глоссарий (8)
- Queue, Topic, Partition, Offset, ISR, Consumer Group, DLQ, Backoff.

## Дополнительно — ссылки
- [Kafka Documentation](https://kafka.apache.org/documentation/)
- [RabbitMQ Tutorials](https://www.rabbitmq.com/getstarted.html)
- [Confluent Schema Registry](https://docs.confluent.io/platform/current/schema-registry/index.html)

## Быстрая практика (3–6 команд)
```bash
# Создать топик
kafka-topics.sh --create --topic demo --partitions 2 --replication-factor 1 --bootstrap-server localhost:9092
# Отправить сообщения
echo "key1:{\"v\":1}" | kafka-console-producer.sh --topic demo --bootstrap-server localhost:9092
# Читать как группа
kafka-console-consumer.sh --topic demo --group test --bootstrap-server localhost:9092 --from-beginning
```
Пояснение: демонстрация создания топика, отправки и чтения с управлением групповым offset.
Проверка: перезапустить консюмер — позиция продолжается с последнего offset.
Типичные ошибки: забытый `--from-beginning` при первоначальном чтении; неверное число партиций для нагрузки.

